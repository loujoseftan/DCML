{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T11:56:15.825350Z",
     "start_time": "2020-09-22T11:56:09.798036Z"
    }
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "findspark.find()\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T11:56:16.343725Z",
     "start_time": "2020-09-22T11:56:16.330731Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.0.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyspark.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T15:48:18.960935Z",
     "start_time": "2020-09-22T15:48:18.954938Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, Tokenizer, StopWordsRemover, HashingTF, IDF, OneHotEncoder, Bucketizer\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, LogisticRegression, GBTClassifier, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator, RegressionEvaluator\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T11:56:27.197930Z",
     "start_time": "2020-09-22T11:56:22.807818Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading `flights` data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T11:56:58.886533Z",
     "start_time": "2020-09-22T11:56:29.516428Z"
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master('local[*]').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T11:57:25.674101Z",
     "start_time": "2020-09-22T11:57:05.807376Z"
    }
   },
   "outputs": [],
   "source": [
    "# read data from csv file\n",
    "flights = spark.read.csv('flights.csv',\n",
    "                         sep=',',\n",
    "                         header=True,\n",
    "                         inferSchema=True,\n",
    "                         nullValue='NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T11:57:51.899199Z",
     "start_time": "2020-09-22T11:57:50.252370Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data contains 50000 records.\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "|mon|dom|dow|carrier|flight|org|mile|depart|duration|delay|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "| 11| 20|  6|     US|    19|JFK|2153|  9.48|     351| null|\n",
      "|  0| 22|  2|     UA|  1107|ORD| 316| 16.33|      82|   30|\n",
      "|  2| 20|  4|     UA|   226|SFO| 337|  6.17|      82|   -8|\n",
      "|  9| 13|  1|     AA|   419|ORD|1236| 10.33|     195|   -5|\n",
      "|  4|  2|  5|     AA|   325|ORD| 258|  8.92|      65| null|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "[('mon', 'int'), ('dom', 'int'), ('dow', 'int'), ('carrier', 'string'), ('flight', 'int'), ('org', 'string'), ('mile', 'int'), ('depart', 'double'), ('duration', 'int'), ('delay', 'int')]\n"
     ]
    }
   ],
   "source": [
    "# get number of records\n",
    "print(f'The data contains {flights.count()} records.')\n",
    "\n",
    "# view the first five records\n",
    "flights.show(5)\n",
    "\n",
    "# check col dtypes\n",
    "print(flights.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading `SMS` spam data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T11:57:52.854294Z",
     "start_time": "2020-09-22T11:57:52.410399Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n",
      "+---+--------------------+-----+\n",
      "| id|                text|label|\n",
      "+---+--------------------+-----+\n",
      "|  1|Sorry, I'll call ...|    0|\n",
      "|  2|Dont worry. I gue...|    0|\n",
      "|  3|Call FREEPHONE 08...|    1|\n",
      "|  4|Win a 1000 cash p...|    1|\n",
      "|  5|Go until jurong p...|    0|\n",
      "+---+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# specify column names and types\n",
    "schema = StructType([\n",
    "    StructField('id', IntegerType()),\n",
    "    StructField('text', StringType()),\n",
    "    StructField('label', IntegerType())\n",
    "])\n",
    "\n",
    "# load data\n",
    "sms = spark.read.csv('sms.csv',\n",
    "                     sep=';',\n",
    "                     header='False',\n",
    "                     schema=schema)\n",
    "\n",
    "sms.printSchema()\n",
    "\n",
    "sms.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing columns and rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T12:06:38.146613Z",
     "start_time": "2020-09-22T12:06:35.622652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing \"delay\" values: 2978\n",
      "remaining rows: 47022\n"
     ]
    }
   ],
   "source": [
    "# remove the 'flight' column\n",
    "flights_drop_col = flights.drop('flight')\n",
    "\n",
    "# number of records with missing 'delay' values\n",
    "print(f'missing \"delay\" values: {flights_drop_col.filter(\"delay IS NULL\").count()}')\n",
    "\n",
    "# remove records with missing 'delay' values\n",
    "flights_valid_delay = flights_drop_col.filter('delay IS NOT NULL')\n",
    "\n",
    "# remove records with missing values in any column and get the number of remaining rows\n",
    "flights_none_missing = flights_valid_delay.dropna()\n",
    "\n",
    "print(f'remaining rows: {flights_none_missing.count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T12:06:41.639028Z",
     "start_time": "2020-09-22T12:06:40.700575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+---+------+--------+-----+------+-----+\n",
      "|mon|dom|dow|carrier|org|depart|duration|delay|    km|label|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+\n",
      "|  0| 22|  2|     UA|ORD| 16.33|      82|   30| 509.0|    1|\n",
      "|  2| 20|  4|     UA|SFO|  6.17|      82|   -8| 542.0|    0|\n",
      "|  9| 13|  1|     AA|ORD| 10.33|     195|   -5|1989.0|    0|\n",
      "|  5|  2|  1|     UA|SFO|  7.98|     102|    2| 885.0|    0|\n",
      "|  7|  2|  6|     AA|ORD| 10.83|     135|   54|1180.0|    1|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert 'mile' to 'km' and drop 'mile' column\n",
    "flights_km = flights_none_missing.withColumn('km', F.round(flights_none_missing.mile * 1.60934)).drop('mile')\n",
    "\n",
    "# create 'label' col indicating whether flight delayed (1) or not (0)\n",
    "flights_km = flights_km.withColumn('label', (flights_km.delay >= 15).cast('integer'))\n",
    "\n",
    "flights_km.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T07:45:43.159115Z",
     "start_time": "2020-09-22T07:45:42.635346Z"
    }
   },
   "source": [
    "## Categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T12:06:48.722647Z",
     "start_time": "2020-09-22T12:06:45.572305Z"
    }
   },
   "outputs": [],
   "source": [
    "# create an indexer\n",
    "indexer = StringIndexer(inputCol='carrier',\n",
    "                        outputCol='carrier_idx')\n",
    "\n",
    "# fit and transform\n",
    "flights_indexed = indexer.fit(flights_km).transform(flights_km)\n",
    "\n",
    "# repeat for 'org' column\n",
    "flights_indexed = StringIndexer(inputCol='org',\n",
    "                                outputCol='org_idx').fit(flights_indexed).transform(flights_indexed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T07:59:24.313591Z",
     "start_time": "2020-09-22T07:59:24.302615Z"
    }
   },
   "source": [
    "## Assembling columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T12:06:49.627580Z",
     "start_time": "2020-09-22T12:06:48.722647Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------+-----+\n",
      "|features                                 |delay|\n",
      "+-----------------------------------------+-----+\n",
      "|[0.0,22.0,2.0,0.0,0.0,509.0,16.33,82.0]  |30   |\n",
      "|[2.0,20.0,4.0,0.0,1.0,542.0,6.17,82.0]   |-8   |\n",
      "|[9.0,13.0,1.0,1.0,0.0,1989.0,10.33,195.0]|-5   |\n",
      "|[5.0,2.0,1.0,0.0,1.0,885.0,7.98,102.0]   |2    |\n",
      "|[7.0,2.0,6.0,1.0,0.0,1180.0,10.83,135.0] |54   |\n",
      "+-----------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create assembler obj\n",
    "input_cols = ['mon', 'dom', 'dow', 'carrier_idx', 'org_idx', 'km', 'depart', 'duration']\n",
    "assembler = VectorAssembler(inputCols=input_cols,\n",
    "                            outputCol='features')\n",
    "\n",
    "# consolidate predictor cols\n",
    "flights_assembled = assembler.transform(flights_indexed)\n",
    "\n",
    "# check\n",
    "flights_assembled.select('features', 'delay').show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T12:06:54.948209Z",
     "start_time": "2020-09-22T12:06:54.762769Z"
    }
   },
   "outputs": [],
   "source": [
    "# split\n",
    "flights_train, flights_test = flights_assembled.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T08:22:16.834234Z",
     "start_time": "2020-09-22T08:22:16.468688Z"
    }
   },
   "source": [
    "## Build a Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T12:08:08.339211Z",
     "start_time": "2020-09-22T12:07:57.305993Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+----------------------------------------+\n",
      "|label|prediction|probability                             |\n",
      "+-----+----------+----------------------------------------+\n",
      "|0    |1.0       |[0.3568002951303492,0.6431997048696507] |\n",
      "|0    |1.0       |[0.3568002951303492,0.6431997048696507] |\n",
      "|1    |1.0       |[0.3568002951303492,0.6431997048696507] |\n",
      "|1    |0.0       |[0.5777899945024739,0.42221000549752613]|\n",
      "|1    |1.0       |[0.3568002951303492,0.6431997048696507] |\n",
      "+-----+----------+----------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create classifier and fit\n",
    "tree = DecisionTreeClassifier()\n",
    "tree_model = tree.fit(flights_train)\n",
    "\n",
    "# predict and inspect\n",
    "preds = tree_model.transform(flights_test)\n",
    "preds.select('label', 'prediction', 'probability').show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T12:08:15.685765Z",
     "start_time": "2020-09-22T12:08:11.759234Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0| 1374|\n",
      "|    0|       0.0| 2542|\n",
      "|    1|       1.0| 3512|\n",
      "|    0|       1.0| 1993|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create conf matrix\n",
    "preds.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T12:08:20.181951Z",
     "start_time": "2020-09-22T12:08:15.688763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc:  64.3%\n"
     ]
    }
   ],
   "source": [
    "# calculate the elements of the confusion matrix\n",
    "TN = preds.filter('prediction = 0 AND label = prediction').count()\n",
    "TP = preds.filter('prediction = 1 AND label = prediction').count()\n",
    "FN = preds.filter('prediction = 0 AND label = 1').count()\n",
    "FP = preds.filter('prediction = 1 AND label = 0').count()\n",
    "\n",
    "print(f'test acc: {(TN + TP) / (TN + TP + FN + FP): .1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T12:08:41.979047Z",
     "start_time": "2020-09-22T12:08:32.712594Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0| 1678|\n",
      "|    0|       0.0| 2584|\n",
      "|    1|       1.0| 3208|\n",
      "|    0|       1.0| 1951|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create and train\n",
    "lr = LogisticRegression().fit(flights_train)\n",
    "\n",
    "# create preds and show conf matrix\n",
    "preds = lr.transform(flights_test)\n",
    "preds.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T12:08:44.979334Z",
     "start_time": "2020-09-22T12:08:41.983044Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc:  61.5%\n"
     ]
    }
   ],
   "source": [
    "# calculate the elements of the confusion matrix\n",
    "TN = preds.filter('prediction = 0 AND label = prediction').count()\n",
    "TP = preds.filter('prediction = 1 AND label = prediction').count()\n",
    "FN = preds.filter('prediction = 0 AND label = 1').count()\n",
    "FP = preds.filter('prediction = 1 AND label = 0').count()\n",
    "\n",
    "print(f'test acc: {(TN + TP) / (TN + TP + FN + FP): .1%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T12:08:44.994019Z",
     "start_time": "2020-09-22T12:08:44.987021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  62.2%\n",
      "recall:  65.7%\n"
     ]
    }
   ],
   "source": [
    "# calculate precision and recall\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "print(f'precision: {precision: .1%}\\nrecall: {recall: .1%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T12:08:48.825563Z",
     "start_time": "2020-09-22T12:08:44.995973Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted precision:  61.4%\n",
      "AUC:  65.4%\n"
     ]
    }
   ],
   "source": [
    "# find weighted precision\n",
    "multi_evaluator = MulticlassClassificationEvaluator()\n",
    "weighted_precision = multi_evaluator.evaluate(preds, {multi_evaluator.metricName: 'weightedPrecision'})\n",
    "\n",
    "# find AUC\n",
    "binary_evaluator = BinaryClassificationEvaluator()\n",
    "auc = binary_evaluator.evaluate(preds, {binary_evaluator.metricName: 'areaUnderROC'})\n",
    "\n",
    "print(f'weighted precision: {weighted_precision: .1%}\\nAUC: {auc: .1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turning Text into Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punctuations, numbers, and tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T12:08:51.872523Z",
     "start_time": "2020-09-22T12:08:51.707620Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------------------------------------------------------------------------------------------------------+-----+\n",
      "|id |text                                                                                                           |label|\n",
      "+---+---------------------------------------------------------------------------------------------------------------+-----+\n",
      "|1  |Sorry, I'll call later in meeting                                                                              |0    |\n",
      "|2  |Dont worry. I guess he's busy.                                                                                 |0    |\n",
      "|3  |Call FREEPHONE 0800 542 0578 now!                                                                              |1    |\n",
      "|4  |Win a 1000 cash prize or a prize worth 5000                                                                    |1    |\n",
      "|5  |Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...|0    |\n",
      "+---+---------------------------------------------------------------------------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sms.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T12:08:53.403226Z",
     "start_time": "2020-09-22T12:08:52.925111Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------------------------------------------------------------------------------------------+-----+---------------------------------------------------------------------------------------------------------------------------+\n",
      "|id |text                                                                                                   |label|words                                                                                                                      |\n",
      "+---+-------------------------------------------------------------------------------------------------------+-----+---------------------------------------------------------------------------------------------------------------------------+\n",
      "|1  |Sorry I'll call later in meeting                                                                       |0    |[sorry, i'll, call, later, in, meeting]                                                                                    |\n",
      "|2  |Dont worry I guess he's busy                                                                           |0    |[dont, worry, i, guess, he's, busy]                                                                                        |\n",
      "|3  |Call FREEPHONE now                                                                                     |1    |[call, freephone, now]                                                                                                     |\n",
      "|4  |Win a cash prize or a prize worth                                                                      |1    |[win, a, cash, prize, or, a, prize, worth]                                                                                 |\n",
      "|5  |Go until jurong point crazy Available only in bugis n great world la e buffet Cine there got amore wat |0    |[go, until, jurong, point, crazy, available, only, in, bugis, n, great, world, la, e, buffet, cine, there, got, amore, wat]|\n",
      "+---+-------------------------------------------------------------------------------------------------------+-----+---------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# remove punctuation and numbers\n",
    "wrangled = sms.withColumn('text', F.regexp_replace(sms.text, '[_():;,.!?\\\\-]', ' '))\n",
    "wrangled = wrangled.withColumn('text', F.regexp_replace(wrangled.text, '[0-9]', ' '))\n",
    "\n",
    "# merge multiple spaces\n",
    "wrangled = wrangled.withColumn('text', F.regexp_replace(wrangled.text, ' +', ' '))\n",
    "\n",
    "# split text into words\n",
    "wrangled = Tokenizer(inputCol='text',\n",
    "                     outputCol='words').transform(wrangled)\n",
    "\n",
    "wrangled.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop words and hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T12:08:54.785358Z",
     "start_time": "2020-09-22T12:08:54.761664Z"
    }
   },
   "outputs": [],
   "source": [
    "sms_ = wrangled.select('id', 'words', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T12:08:57.168044Z",
     "start_time": "2020-09-22T12:08:55.327691Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+----------------------------------------------------------------------------------------------------+\n",
      "|terms                           |features                                                                                            |\n",
      "+--------------------------------+----------------------------------------------------------------------------------------------------+\n",
      "|[sorry, call, later, meeting]   |(1024,[138,384,577,996],[2.273418200008753,3.6288353225642043,3.5890949939146903,4.104259019279279])|\n",
      "|[dont, worry, guess, busy]      |(1024,[215,233,276,329],[3.9913186080986836,3.3790235241678332,4.734227298217693,4.58299632849377]) |\n",
      "|[call, freephone]               |(1024,[133,138],[5.367951058306837,2.273418200008753])                                              |\n",
      "|[win, cash, prize, prize, worth]|(1024,[31,47,62,389],[3.6632029660684124,4.754846585420428,4.072170704727778,7.064594791043114])    |\n",
      "+--------------------------------+----------------------------------------------------------------------------------------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# remove stop words\n",
    "wrangled = StopWordsRemover(inputCol='words',\n",
    "                            outputCol='terms').transform(sms_)\n",
    "\n",
    "# apply hashing\n",
    "wrangled = HashingTF(inputCol='terms',\n",
    "                     outputCol='hash',\n",
    "                     numFeatures=1024).transform(wrangled)\n",
    "\n",
    "# convert to TF-IDF\n",
    "tf_idf = IDF(inputCol='hash',\n",
    "             outputCol='features').fit(wrangled).transform(wrangled)\n",
    "\n",
    "tf_idf.select('terms', 'features').show(4, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T09:17:33.712975Z",
     "start_time": "2020-09-22T09:17:33.524081Z"
    }
   },
   "source": [
    "## Training a spam classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T12:08:57.192029Z",
     "start_time": "2020-09-22T12:08:57.172041Z"
    }
   },
   "outputs": [],
   "source": [
    "# split\n",
    "sms_train, sms_test = tf_idf.randomSplit([0.8, 0.2], seed=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T12:09:03.070691Z",
     "start_time": "2020-09-22T12:08:57.232082Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0|   41|\n",
      "|    0|       0.0|  948|\n",
      "|    1|       1.0|  105|\n",
      "|    0|       1.0|    2|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit logreg model and eval\n",
    "lr = LogisticRegression(regParam=0.2).fit(sms_train)\n",
    "\n",
    "preds = lr.transform(sms_test)\n",
    "\n",
    "preds.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding flight origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T12:38:58.196259Z",
     "start_time": "2020-09-22T12:38:57.818620Z"
    }
   },
   "outputs": [],
   "source": [
    "flights_ = StringIndexer(inputCol='org',\n",
    "                         outputCol='org_idx').fit(flights).transform(flights)\n",
    "\n",
    "flights_ = flights_.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T12:39:04.210434Z",
     "start_time": "2020-09-22T12:39:02.280155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-------------+\n",
      "|org|org_idx|    org_dummy|\n",
      "+---+-------+-------------+\n",
      "|ORD|    0.0|(7,[0],[1.0])|\n",
      "|SFO|    1.0|(7,[1],[1.0])|\n",
      "|JFK|    2.0|(7,[2],[1.0])|\n",
      "|LGA|    3.0|(7,[3],[1.0])|\n",
      "|SJC|    4.0|(7,[4],[1.0])|\n",
      "|SMF|    5.0|(7,[5],[1.0])|\n",
      "|TUS|    6.0|(7,[6],[1.0])|\n",
      "|OGG|    7.0|    (7,[],[])|\n",
      "+---+-------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# instantiate one hot encoder\n",
    "onehot = OneHotEncoder(inputCols=['org_idx'],\n",
    "                       outputCols=['org_dummy'])\n",
    "\n",
    "# apply to data\n",
    "flights_onehot = onehot.fit(flights_).transform(flights_)\n",
    "\n",
    "flights_onehot.select('org', 'org_idx', 'org_dummy').distinct().sort('org_idx').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T12:42:31.146558Z",
     "start_time": "2020-09-22T12:42:31.108517Z"
    }
   },
   "outputs": [],
   "source": [
    "flights_onehot = flights_onehot.withColumn('km', F.round(flights_onehot.mile * 1.60934)).drop('mile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T12:44:20.639462Z",
     "start_time": "2020-09-22T12:44:20.605463Z"
    }
   },
   "outputs": [],
   "source": [
    "flights_prep = VectorAssembler(inputCols=['km'],\n",
    "                               outputCol='features').transform(flights_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T12:44:55.125013Z",
     "start_time": "2020-09-22T12:44:55.110001Z"
    }
   },
   "outputs": [],
   "source": [
    "flights_train, flights_test = flights_prep.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flight duration model: just using `km`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T12:48:35.241251Z",
     "start_time": "2020-09-22T12:48:30.138835Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|duration|prediction        |\n",
      "+--------+------------------+\n",
      "|560     |561.0619125749561 |\n",
      "|310     |346.9912658584909 |\n",
      "|165     |133.37496080467133|\n",
      "|120     |133.37496080467133|\n",
      "|240     |213.26336981983607|\n",
      "+--------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "RMSE:  16.92\n"
     ]
    }
   ],
   "source": [
    "# create regression model and fit\n",
    "lr = LinearRegression(labelCol='duration').fit(flights_train)\n",
    "\n",
    "# eval\n",
    "preds = lr.transform(flights_test)\n",
    "preds.select('duration', 'prediction').show(5, False)\n",
    "\n",
    "print(f'RMSE: {RegressionEvaluator(labelCol=\"duration\").evaluate(preds): .2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T12:56:19.582828Z",
     "start_time": "2020-09-22T12:56:19.499002Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept: 44.02110048439229\n",
      "coefs: [0.07572361044091444]\n",
      "mins per km: 0.07572361044091444\n",
      "avg speed: 792.3552462783949\n"
     ]
    }
   ],
   "source": [
    "# intercept\n",
    "inter = lr.intercept\n",
    "print(f'intercept: {inter}')\n",
    "\n",
    "# coefs\n",
    "coefs = lr.coefficients\n",
    "print(f'coefs: {coefs}')\n",
    "\n",
    "# average mins per km\n",
    "min_per_km = lr.coefficients[0]\n",
    "print(f'mins per km: {min_per_km}')\n",
    "\n",
    "# average speed in kph\n",
    "avg_speed = 60 / min_per_km\n",
    "print(f'avg speed: {avg_speed}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flight duration model: adding origin airport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T13:01:11.514615Z",
     "start_time": "2020-09-22T13:01:11.459648Z"
    }
   },
   "outputs": [],
   "source": [
    "flights_prep = VectorAssembler(inputCols=['km', 'org_dummy'],\n",
    "                               outputCol='features').transform(flights_onehot)\n",
    "\n",
    "flights_train, flights_test = flights_prep.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T13:03:34.505243Z",
     "start_time": "2020-09-22T13:03:30.884096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  11.02\n"
     ]
    }
   ],
   "source": [
    "# create regressor, fit, eval\n",
    "lr = LinearRegression(labelCol='duration').fit(flights_train)\n",
    "\n",
    "preds = lr.transform(flights_test)\n",
    "\n",
    "print(f'RMSE: {RegressionEvaluator(labelCol=\"duration\").evaluate(preds): .2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T13:08:00.326130Z",
     "start_time": "2020-09-22T13:08:00.309139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept: 15.51432820470039\n",
      "coefs: [0.0743187885664477,28.85360121411286,20.804901599913148,52.63560265547631,47.08803307610951,18.577771019304308,15.957548580589801,18.400432009994915]\n"
     ]
    }
   ],
   "source": [
    "# intercept\n",
    "inter = lr.intercept\n",
    "print(f'intercept: {inter}')\n",
    "\n",
    "# coefs\n",
    "coefs = lr.coefficients\n",
    "print(f'coefs: {coefs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T13:16:05.660342Z",
     "start_time": "2020-09-22T13:16:05.644694Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg speed:  807.33\n",
      "avg mins on ground at OGG:  15.51\n",
      "avg mins on ground at JFK:  68.15\n",
      "avg mins on ground at LGA:  62.60\n"
     ]
    }
   ],
   "source": [
    "# avg speed in kph\n",
    "avg_speed = 60 / coefs[0]\n",
    "print(f'avg speed: {avg_speed: .2f}')\n",
    "\n",
    "# avg mins on ground at OGG (reference dummy for org)\n",
    "print(f'avg mins on ground at OGG: {inter: .2f}')\n",
    "\n",
    "# avg mins at JFK\n",
    "avg_jfk = inter + coefs[3]\n",
    "print(f'avg mins on ground at JFK: {avg_jfk: .2f}')\n",
    "\n",
    "# avg mins at LGA\n",
    "avg_lga = inter + coefs[4]\n",
    "print(f'avg mins on ground at LGA: {avg_lga: .2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bucketing & Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bucketing departure time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T13:38:49.811656Z",
     "start_time": "2020-09-22T13:38:49.284508Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+\n",
      "|depart|depart_bucket|\n",
      "+------+-------------+\n",
      "| 16.33|          5.0|\n",
      "|  6.17|          2.0|\n",
      "| 10.33|          3.0|\n",
      "|  7.98|          2.0|\n",
      "| 10.83|          3.0|\n",
      "+------+-------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------+-------------+-------------+\n",
      "|depart|depart_bucket| depart_dummy|\n",
      "+------+-------------+-------------+\n",
      "| 16.33|          5.0|(7,[5],[1.0])|\n",
      "|  6.17|          2.0|(7,[2],[1.0])|\n",
      "| 10.33|          3.0|(7,[3],[1.0])|\n",
      "|  7.98|          2.0|(7,[2],[1.0])|\n",
      "| 10.83|          3.0|(7,[3],[1.0])|\n",
      "+------+-------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create buckets at 3 hr intervals\n",
    "buckets = Bucketizer(splits=list(range(0, 25, 3)),\n",
    "                     inputCol='depart',\n",
    "                     outputCol='depart_bucket')\n",
    "\n",
    "# bucket the departure times\n",
    "bucketed = buckets.transform(flights_onehot)\n",
    "bucketed.select('depart', 'depart_bucket').show(5)\n",
    "\n",
    "# one-hot encode\n",
    "onehot = OneHotEncoder(inputCols=['depart_bucket'],\n",
    "                       outputCols=['depart_dummy'])\n",
    "\n",
    "flights_oh = onehot.fit(bucketed).transform(bucketed)\n",
    "flights_oh.select('depart', 'depart_bucket', 'depart_dummy').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T13:32:52.072969Z",
     "start_time": "2020-09-22T13:32:51.504879Z"
    }
   },
   "source": [
    "## Flight duration model: adding departure time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T13:41:00.657323Z",
     "start_time": "2020-09-22T13:41:00.618331Z"
    }
   },
   "outputs": [],
   "source": [
    "flights_prep = VectorAssembler(inputCols=['km', 'org_dummy', 'depart_dummy'],\n",
    "                               outputCol='features').transform(flights_oh)\n",
    "\n",
    "flights_train, flights_test = flights_prep.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T13:41:11.410936Z",
     "start_time": "2020-09-22T13:41:05.495450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  10.73\n"
     ]
    }
   ],
   "source": [
    "# create regressor, fit, eval\n",
    "lr = LinearRegression(labelCol='duration').fit(flights_train)\n",
    "\n",
    "preds = lr.transform(flights_test)\n",
    "\n",
    "print(f'RMSE: {RegressionEvaluator(labelCol=\"duration\").evaluate(preds): .2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T13:46:35.978182Z",
     "start_time": "2020-09-22T13:46:35.944202Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg mins on ground at OGG for 21:00-24:00:  10.01\n",
      "avg mins on ground at OGG for 00:00-03:00: -4.85\n",
      "avg mins on ground at JFK for 00:00-03:00:  46.91\n"
     ]
    }
   ],
   "source": [
    "# avg mins on ground at OGG for flights departing between 21:00 and 24:00 (reference)\n",
    "avg_eve_ogg = lr.intercept\n",
    "print(f'avg mins on ground at OGG for 21:00-24:00: {avg_eve_ogg: .2f}')\n",
    "\n",
    "# avg mins on ground at OGG for flights departing between 00:00 and 03:00\n",
    "avg_night_ogg = lr.intercept + lr.coefficients[8]\n",
    "print(f'avg mins on ground at OGG for 00:00-03:00: {avg_night_ogg: .2f}')\n",
    "\n",
    "# Average minutes on ground at JFK for flights departing between 00:00 and 03:00\n",
    "avg_night_jfk = lr.intercept + lr.coefficients[3] + lr.coefficients[8]\n",
    "print(f'avg mins on ground at JFK for 00:00-03:00: {avg_night_jfk: .2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flight duration model: More features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T14:01:26.012006Z",
     "start_time": "2020-09-22T14:01:25.324417Z"
    }
   },
   "outputs": [],
   "source": [
    "# one-hot encode\n",
    "onehot = OneHotEncoder(inputCols=['dow', 'mon'],\n",
    "                       outputCols=['dow_dummy', 'mon_dummy'])\n",
    "\n",
    "flights_oh = onehot.fit(flights_oh).transform(flights_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T14:07:44.728373Z",
     "start_time": "2020-09-22T14:07:44.617438Z"
    }
   },
   "outputs": [],
   "source": [
    "flights_prep = VectorAssembler(inputCols=['km', 'org_dummy', 'depart_dummy', 'dow_dummy', 'mon_dummy'],\n",
    "                               outputCol='features').transform(flights_oh)\n",
    "\n",
    "flights_train, flights_test = flights_prep.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T14:09:57.096767Z",
     "start_time": "2020-09-22T14:09:51.524156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  10.64\n"
     ]
    }
   ],
   "source": [
    "# create regressor, fit, eval\n",
    "lr = LinearRegression(labelCol='duration').fit(flights_train)\n",
    "\n",
    "preds = lr.transform(flights_test)\n",
    "\n",
    "print(f'RMSE: {RegressionEvaluator(labelCol=\"duration\").evaluate(preds): .2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T14:10:35.292816Z",
     "start_time": "2020-09-22T14:10:35.276829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07442209559515502,27.659450151115774,20.45918930623718,51.85957014048378,46.18664461701692,17.845461098188387,15.340633664518776,17.905358631225713,-15.273418440592236,0.7300571207888041,4.131977434639745,7.126546170088426,4.664162537576813,8.83969858386643,8.806754088197247,0.46746560369110074,0.16539185557587052,-0.25012969981315836,0.19119328659810572,0.17211666989806534,0.05606261143314675,-2.1461312335803973,-2.3902244741875878,-2.1572730021883637,-3.787912634052201,-4.2281201026909425,-4.44040786158588,-4.62143727685574,-4.463261506930194,-4.026770099104065,-2.831627030737389,-0.8592174134481364]\n"
     ]
    }
   ],
   "source": [
    "# look at model coefficients\n",
    "coefs = lr.coefficients\n",
    "print(coefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flight duration model: Regularization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T14:14:42.753074Z",
     "start_time": "2020-09-22T14:14:38.012126Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  11.55\n"
     ]
    }
   ],
   "source": [
    "# create regressor, fit, eval\n",
    "\n",
    "# Lasso Regression\n",
    "lr = LinearRegression(labelCol='duration',\n",
    "                      regParam=1,\n",
    "                      elasticNetParam=1).fit(flights_train)\n",
    "\n",
    "preds = lr.transform(flights_test)\n",
    "\n",
    "print(f'RMSE: {RegressionEvaluator(labelCol=\"duration\").evaluate(preds): .2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T14:15:55.669347Z",
     "start_time": "2020-09-22T14:15:55.014438Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0735413151602253,5.697832374535206,0.0,28.90193980919395,22.063034341417183,0.0,-2.289374478161381,0.0,0.0,0.0,0.0,0.0,0.0,1.005851813807962,1.1028050009787465,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
      "No. of zero coefficients: 25\n"
     ]
    }
   ],
   "source": [
    "# look at coefs\n",
    "coefs = lr.coefficients\n",
    "print(coefs)\n",
    "\n",
    "# number of zero coefs\n",
    "zero_cs = sum([beta == 0 for beta in coefs])\n",
    "print(f'No. of zero coefficients: {zero_cs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T14:25:27.517074Z",
     "start_time": "2020-09-22T14:25:27.440136Z"
    }
   },
   "outputs": [],
   "source": [
    "flights_ = flights.dropna()\n",
    "flights_ = flights_.withColumn('km', F.round(flights_.mile * 1.60934)).drop('mile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T14:34:33.588589Z",
     "start_time": "2020-09-22T14:34:33.521433Z"
    }
   },
   "outputs": [],
   "source": [
    "flights_train, flights_test = flights_.randomSplit([0.8, 0.2], seed=1111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T14:25:34.857427Z",
     "start_time": "2020-09-22T14:25:34.559591Z"
    }
   },
   "source": [
    "## Flight duration model: pipeline stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T14:31:19.887780Z",
     "start_time": "2020-09-22T14:31:19.779842Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert categorical strings to index values\n",
    "indexer = StringIndexer(inputCol='org',\n",
    "                        outputCol='org_idx')\n",
    "\n",
    "# one-hot encode index values\n",
    "onehot = OneHotEncoder(inputCols=['org_idx', 'dow'],\n",
    "                       outputCols=['org_dummy', 'dow_dummy'])\n",
    "\n",
    "# assemble predictors\n",
    "assembler = VectorAssembler(inputCols=['km', 'org_dummy', 'dow_dummy'],\n",
    "                            outputCol='features')\n",
    "\n",
    "# linear regression\n",
    "regression = LinearRegression(labelCol='duration')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flight duration model: pipeline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T14:35:40.304399Z",
     "start_time": "2020-09-22T14:35:35.720279Z"
    }
   },
   "outputs": [],
   "source": [
    "# construct pipeline\n",
    "pipeline = Pipeline(stages=[indexer,\n",
    "                            onehot,\n",
    "                            assembler,\n",
    "                            regression])\n",
    "\n",
    "# train\n",
    "pipeline = pipeline.fit(flights_train)\n",
    "\n",
    "# predict\n",
    "preds = pipeline.transform(flights_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMS spam pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T14:42:08.310412Z",
     "start_time": "2020-09-22T14:42:07.809351Z"
    }
   },
   "outputs": [],
   "source": [
    "# break text into tokens at non-word characters\n",
    "tokenizer = Tokenizer(inputCol='text',\n",
    "                      outputCol='words')\n",
    "\n",
    "# remove stop words\n",
    "remover = StopWordsRemover(inputCol=tokenizer.getOutputCol(),\n",
    "                           outputCol='terms')\n",
    "\n",
    "# apply hashing, transform to tf-idf\n",
    "hasher = HashingTF(inputCol=remover.getOutputCol(),\n",
    "                   outputCol='hash')\n",
    "idf = IDF(inputCol=hasher.getOutputCol(),\n",
    "          outputCol='features')\n",
    "\n",
    "# create logreg obj pipeline\n",
    "logistic = LogisticRegression()\n",
    "pipeline = Pipeline(stages=[tokenizer,\n",
    "                            remover,\n",
    "                            hasher,\n",
    "                            idf,\n",
    "                            logistic])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T14:49:03.994863Z",
     "start_time": "2020-09-22T14:49:03.795980Z"
    }
   },
   "outputs": [],
   "source": [
    "flights_prep = VectorAssembler(inputCols=['km'],\n",
    "                               outputCol='features').transform(flights_)\n",
    "\n",
    "flights_train, flights_test = flights_prep.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validating simple flight duration model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T14:53:18.644957Z",
     "start_time": "2020-09-22T14:53:03.868039Z"
    }
   },
   "outputs": [],
   "source": [
    "# create an empty parameter grid\n",
    "params = ParamGridBuilder().build()\n",
    "\n",
    "# create objects for building and evaluating a regression model\n",
    "regression = LinearRegression(labelCol='duration')\n",
    "evaluator = RegressionEvaluator(labelCol='duration')\n",
    "\n",
    "# create a cross validator\n",
    "cv = CrossValidator(estimator=regression, \n",
    "                    estimatorParamMaps=params,\n",
    "                    evaluator=evaluator, \n",
    "                    numFolds=5)\n",
    "\n",
    "# Train and test model on multiple folds of the training data\n",
    "cv = cv.fit(flights_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validating flight duration model pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T15:03:59.373033Z",
     "start_time": "2020-09-22T15:03:59.266078Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create an indexer for the org field\n",
    "indexer = StringIndexer(inputCol='org', \n",
    "                        outputCol='org_idx')\n",
    "\n",
    "# Create an one-hot encoder for the indexed org field\n",
    "onehot = OneHotEncoder(inputCols=['org_idx'], \n",
    "                       outputCols=['org_dummy'])\n",
    "\n",
    "# Assemble the km and one-hot encoded fields\n",
    "assembler = VectorAssembler(inputCols=['km', 'org_dummy'], \n",
    "                            outputCol='features')\n",
    "\n",
    "# Create a pipeline and cross-validator.\n",
    "pipeline = Pipeline(stages=[indexer, \n",
    "                            onehot, \n",
    "                            assembler, \n",
    "                            regression])\n",
    "cv = CrossValidator(estimator=pipeline,\n",
    "                    estimatorParamMaps=params,\n",
    "                    evaluator=evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T15:11:16.148216Z",
     "start_time": "2020-09-22T15:11:16.040281Z"
    }
   },
   "outputs": [],
   "source": [
    "flights_ = flights.dropna()\n",
    "flights_ = flights_.withColumn('km', F.round(flights_.mile * 1.60934)).drop('mile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T15:11:28.154118Z",
     "start_time": "2020-09-22T15:11:28.138109Z"
    }
   },
   "outputs": [],
   "source": [
    "flights_train, flights_test = flights_.randomSplit([0.8, 0.2], seed=1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T15:12:03.846738Z",
     "start_time": "2020-09-22T15:12:03.807762Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert categorical strings to index values\n",
    "indexer = StringIndexer(inputCol='org',\n",
    "                        outputCol='org_idx')\n",
    "\n",
    "# one-hot encode index values\n",
    "onehot = OneHotEncoder(inputCols=['org_idx', 'dow'],\n",
    "                       outputCols=['org_dummy', 'dow_dummy'])\n",
    "\n",
    "# assemble predictors\n",
    "assembler = VectorAssembler(inputCols=['km', 'org_dummy', 'dow_dummy'],\n",
    "                            outputCol='features')\n",
    "\n",
    "# linear regression\n",
    "regression = LinearRegression(labelCol='duration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T15:12:44.517089Z",
     "start_time": "2020-09-22T15:12:44.503097Z"
    }
   },
   "outputs": [],
   "source": [
    "# construct pipeline\n",
    "pipeline = Pipeline(stages=[indexer,\n",
    "                            onehot,\n",
    "                            assembler,\n",
    "                            regression])\n",
    "\n",
    "# create evaluator\n",
    "evaluator = RegressionEvaluator(labelCol='duration')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing flights linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T15:21:33.108896Z",
     "start_time": "2020-09-22T15:21:33.064920Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models to be tested:  12\n"
     ]
    }
   ],
   "source": [
    "# Create parameter grid\n",
    "params = ParamGridBuilder()\n",
    "\n",
    "# Add grids for two parameters\n",
    "params = params.addGrid(regression.regParam, [0.01, 0.1, 1.0, 10.0]) \\\n",
    "               .addGrid(regression.elasticNetParam, [0, 0.5, 1.0])\n",
    "\n",
    "# Build the parameter grid\n",
    "params = params.build()\n",
    "print('Number of models to be tested: ', len(params))\n",
    "\n",
    "# Create cross-validator\n",
    "cv = CrossValidator(estimator=pipeline, \n",
    "                    estimatorParamMaps=params, \n",
    "                    evaluator=evaluator, \n",
    "                    numFolds=5,\n",
    "                    seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T15:26:43.165512Z",
     "start_time": "2020-09-22T15:25:41.519635Z"
    }
   },
   "outputs": [],
   "source": [
    "models = cv.fit(flights_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dissecting the best flight duration model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T15:28:50.899943Z",
     "start_time": "2020-09-22T15:28:50.176413Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StringIndexerModel: uid=StringIndexer_f549479cb0f9, handleInvalid=error, OneHotEncoderModel: uid=OneHotEncoder_8fcc2a9851ca, dropLast=true, handleInvalid=error, numInputCols=2, numOutputCols=2, VectorAssembler_03651ecb7156, LinearRegressionModel: uid=LinearRegression_388900a404f6, numFeatures=14]\n",
      "RMSE:  10.96\n"
     ]
    }
   ],
   "source": [
    "# get the best model from cv\n",
    "best_model = models.bestModel\n",
    "\n",
    "# look at stages\n",
    "print(best_model.stages)\n",
    "\n",
    "# generate preds\n",
    "preds = best_model.transform(flights_test)\n",
    "print(f'RMSE: {evaluator.evaluate(preds): .2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMS spam optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T15:32:19.648367Z",
     "start_time": "2020-09-22T15:32:19.616053Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create parameter grid\n",
    "params = ParamGridBuilder()\n",
    "\n",
    "# Add grid for hashing trick parameters\n",
    "params = params.addGrid(hasher.numFeatures, [1024, 4096, 16384]) \\\n",
    "               .addGrid(hasher.binary, [True, False])\n",
    "\n",
    "# Add grid for logistic regression parameters\n",
    "params = params.addGrid(logistic.regParam, [0.01, 0.1, 1.0, 10.0]) \\\n",
    "               .addGrid(logistic.elasticNetParam, [0.0, 0.5, 1.0])\n",
    "\n",
    "# Build parameter grid\n",
    "params = params.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delayed flights with Gradient-Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T15:41:41.265604Z",
     "start_time": "2020-09-22T15:41:41.074748Z"
    }
   },
   "outputs": [],
   "source": [
    "flights_ = flights.dropna()\n",
    "flights_ = flights_.withColumn('label', (flights_.delay >= 15).cast('integer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T15:42:44.509082Z",
     "start_time": "2020-09-22T15:42:44.469105Z"
    }
   },
   "outputs": [],
   "source": [
    "flights_prep = VectorAssembler(inputCols=['mon', 'depart', 'duration'],\n",
    "                               outputCol='features').transform(flights_)\n",
    "\n",
    "flights_train, flights_test = flights_prep.randomSplit([0.8, 0.2], seed=1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T15:47:30.914491Z",
     "start_time": "2020-09-22T15:47:15.463558Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC:  62.0%\n",
      "AUROC:  67.1%\n",
      "no. of trees in gbt: 20\n",
      "feature importances: (3,[0,1,2],[0.34928613199830205,0.3171833965819637,0.33353047141973424])\n"
     ]
    }
   ],
   "source": [
    "# Create model objects and train on training data\n",
    "tree = DecisionTreeClassifier().fit(flights_train)\n",
    "gbt = GBTClassifier().fit(flights_train)\n",
    "\n",
    "# Compare AUC on testing data\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "print(f'AUROC: {evaluator.evaluate(tree.transform(flights_test)): .1%}')\n",
    "print(f'AUROC: {evaluator.evaluate(gbt.transform(flights_test)): .1%}')\n",
    "\n",
    "# Find the number of trees and the relative importance of features\n",
    "print(f'no. of trees in gbt: {len(gbt.trees)}')\n",
    "print(f'feature importances: {gbt.featureImportances}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delayed flights with a Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T15:50:30.391240Z",
     "start_time": "2020-09-22T15:50:29.833284Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a random forest classifier\n",
    "forest = RandomForestClassifier()\n",
    "\n",
    "# Create a parameter grid\n",
    "params = ParamGridBuilder() \\\n",
    "            .addGrid(forest.featureSubsetStrategy, ['all', 'onethird', 'sqrt', 'log2']) \\\n",
    "            .addGrid(forest.maxDepth, [2, 5, 10]) \\\n",
    "            .build()\n",
    "\n",
    "# Create a binary classification evaluator\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "\n",
    "# Create a cross-validator\n",
    "cv = CrossValidator(estimator=forest, \n",
    "                    estimatorParamMaps=params,\n",
    "                    evaluator=evaluator, \n",
    "                    numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T15:53:53.857763Z",
     "start_time": "2020-09-22T15:50:58.888393Z"
    }
   },
   "outputs": [],
   "source": [
    "models = cv.fit(flights_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T15:56:37.018623Z",
     "start_time": "2020-09-22T15:56:36.141377Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg AUROC for best model:  67.6%\n",
      "optimal max depth: maxDepth: Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. (default: 5, current: 10)\n",
      "optimal feature subset strat: featureSubsetStrategy: The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto' (default: auto, current: onethird)\n",
      "test AUROC:  67.6%\n"
     ]
    }
   ],
   "source": [
    "# Average AUC for each parameter combination in grid\n",
    "avg_auc = models.avgMetrics\n",
    "\n",
    "# Average AUC for the best model\n",
    "best_model_auc =  max(avg_auc)\n",
    "print(f'avg AUROC for best model: {best_model_auc: .1%}')\n",
    "\n",
    "# What's the optimal parameter value?\n",
    "opt_max_depth = models.bestModel.explainParam('maxDepth')\n",
    "print(f'optimal max depth: {opt_max_depth}')\n",
    "opt_feat_substrat = models.bestModel.explainParam('featureSubsetStrategy')\n",
    "print(f'optimal feature subset strat: {opt_feat_substrat}')\n",
    "\n",
    "# AUC for best model on testing data\n",
    "best_auc = evaluator.evaluate(models.bestModel.transform(flights_test))\n",
    "print(f'test AUROC: {best_auc: .1%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2-gpu",
   "language": "python",
   "name": "tf2-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
