{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T13:40:23.584630Z",
     "start_time": "2020-09-04T13:40:08.228981Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T14:20:27.047319Z",
     "start_time": "2020-09-04T14:20:26.781475Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T13:47:25.182730Z",
     "start_time": "2020-09-04T13:47:25.042829Z"
    }
   },
   "outputs": [],
   "source": [
    "overviews = pd.read_csv('./movie_overviews.csv')\n",
    "reviews = pd.read_csv('./movie_reviews_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a bag-of-words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T13:54:11.570202Z",
     "start_time": "2020-09-04T13:54:11.557213Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>overview</th>\n",
       "      <th>tagline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>862</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8844</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>Roll the dice and unleash the excitement!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15602</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>Still Yelling. Still Fighting. Still Ready for...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id             title                                           overview  \\\n",
       "0    862         Toy Story  Led by Woody, Andy's toys live happily in his ...   \n",
       "1   8844           Jumanji  When siblings Judy and Peter discover an encha...   \n",
       "2  15602  Grumpier Old Men  A family wedding reignites the ancient feud be...   \n",
       "\n",
       "                                             tagline  \n",
       "0                                                NaN  \n",
       "1          Roll the dice and unleash the excitement!  \n",
       "2  Still Yelling. Still Fighting. Still Ready for...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overviews.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T13:54:19.255929Z",
     "start_time": "2020-09-04T13:54:19.067725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9099 entries, 0 to 9098\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        9099 non-null   int64 \n",
      " 1   title     9099 non-null   object\n",
      " 2   overview  9087 non-null   object\n",
      " 3   tagline   7033 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 284.5+ KB\n"
     ]
    }
   ],
   "source": [
    "overviews.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BoW model for movie taglines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T13:57:14.638048Z",
     "start_time": "2020-09-04T13:57:14.615041Z"
    }
   },
   "outputs": [],
   "source": [
    "overviews_ = overviews.copy().dropna()\n",
    "overviews_['tagline'] = overviews_['tagline'].str.lower()\n",
    "\n",
    "corpus = overviews_['tagline'] #we'll be using this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T13:57:27.901804Z",
     "start_time": "2020-09-04T13:57:27.894809Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1            roll the dice and unleash the excitement!\n",
       "2    still yelling. still fighting. still ready for...\n",
       "3    friends are the people who let you be yourself...\n",
       "4    just when his world is back to normal... he's ...\n",
       "5                             a los angeles crime saga\n",
       "Name: tagline, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T13:59:46.417822Z",
     "start_time": "2020-09-04T13:59:45.891890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7033, 6614)\n"
     ]
    }
   ],
   "source": [
    "# create CountVectorizer object\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# generate matrix of word vectors\n",
    "bow_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "print(bow_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing dimensionality and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T14:20:33.675196Z",
     "start_time": "2020-09-04T14:20:31.351382Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "stopwords = spacy.lang.en.stop_words.STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T14:05:01.052056Z",
     "start_time": "2020-09-04T14:05:01.047055Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    lemmas = [token.lemma_ for token in doc]\n",
    "    a_lemmas = [lemma for lemma in lemmas\n",
    "                if lemma.isalpha() and lemma not in stopwords]\n",
    "    return \" \".join(a_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T14:06:50.126553Z",
     "start_time": "2020-09-04T14:05:33.917591Z"
    }
   },
   "outputs": [],
   "source": [
    "lem_corpus = corpus.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T14:07:03.135615Z",
     "start_time": "2020-09-04T14:07:03.127624Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    roll dice unleash excitement\n",
       "2           yell fight ready love\n",
       "3    friend people let let forget\n",
       "4      world normal surprise life\n",
       "5          los angeles crime saga\n",
       "Name: tagline, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lem_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T14:10:37.621938Z",
     "start_time": "2020-09-04T14:10:37.614942Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7033,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lem_corpus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T14:12:20.434943Z",
     "start_time": "2020-09-04T14:12:20.335000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7033, 4964)\n"
     ]
    }
   ],
   "source": [
    "# create another vectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# generate a matrix of word vectors\n",
    "bow_lem_matrix = vectorizer.fit_transform(lem_corpus)\n",
    "\n",
    "print(bow_lem_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the number of features have reduced significantly from around 6600 to **4964** for pre-processed movie taglines. The reduced number of dimensions on account of text preprocessing usually leads to better performance when conducting machine learning and it is a good idea to consider it. However, as mentioned in a previous lesson, the final decision always depends on the nature of the application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping feature indices with feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T14:14:11.442284Z",
     "start_time": "2020-09-04T14:14:11.439284Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus = ['The lion is the king of the jungle',\n",
    "          'Lions have lifespans of a decade', \n",
    "          'The lion is an endangered species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T14:15:45.773661Z",
     "start_time": "2020-09-04T14:15:45.754672Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>an</th>\n",
       "      <th>decade</th>\n",
       "      <th>endangered</th>\n",
       "      <th>have</th>\n",
       "      <th>is</th>\n",
       "      <th>jungle</th>\n",
       "      <th>king</th>\n",
       "      <th>lifespans</th>\n",
       "      <th>lion</th>\n",
       "      <th>lions</th>\n",
       "      <th>of</th>\n",
       "      <th>species</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   an  decade  endangered  have  is  jungle  king  lifespans  lion  lions  of  \\\n",
       "0   0       0           0     0   1       1     1          0     1      0   1   \n",
       "1   0       1           0     1   0       0     0          1     0      1   1   \n",
       "2   1       0           1     0   1       0     0          0     1      0   0   \n",
       "\n",
       "   species  the  \n",
       "0        0    3  \n",
       "1        0    0  \n",
       "2        1    1  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create CountVectorizer object\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# generate matrix of word vectors\n",
    "bow_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# convert bow_matrix into a DataFrame\n",
    "bow_df = pd.DataFrame(bow_matrix.toarray())\n",
    "\n",
    "# map the column names to vocabulary \n",
    "bow_df.columns = vectorizer.get_feature_names()\n",
    "\n",
    "bow_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a BoW Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BoW vectors for movie reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T14:23:38.708721Z",
     "start_time": "2020-09-04T14:23:38.695731Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this anime series starts out great interesting...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>some may go for a film like this but i most as...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i ve seen this piece of perfection during the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this movie is likely the worst movie i ve ever...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it ll soon be 10 yrs since this movie was rele...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  this anime series starts out great interesting...          0\n",
       "1  some may go for a film like this but i most as...          0\n",
       "2  i ve seen this piece of perfection during the ...          1\n",
       "3  this movie is likely the worst movie i ve ever...          0\n",
       "4  it ll soon be 10 yrs since this movie was rele...          1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(reviews.shape)\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T14:31:12.966260Z",
     "start_time": "2020-09-04T14:31:12.957264Z"
    }
   },
   "outputs": [],
   "source": [
    "X = reviews['review']\n",
    "y = reviews['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.75,\n",
    "                                                    random_state=1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T14:31:13.620843Z",
     "start_time": "2020-09-04T14:31:13.333212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (250, 7317)\n",
      "test shape: (750, 7317)\n"
     ]
    }
   ],
   "source": [
    "# create CountVectorizer object\n",
    "vectorizer = CountVectorizer(lowercase=True,\n",
    "                             stop_words='english')\n",
    "\n",
    "# transform data\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "X_test_bow = vectorizer.transform(X_test)\n",
    "\n",
    "print(f'train shape: {X_train_bow.shape}')\n",
    "print(f'test shape: {X_test_bow.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the sentiment of a movie review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T14:31:14.075988Z",
     "start_time": "2020-09-04T14:31:14.064994Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc:  80.1%\n"
     ]
    }
   ],
   "source": [
    "# create a MultinomialNB object\n",
    "nb = MultinomialNB()\n",
    "\n",
    "# fit and eval\n",
    "nb.fit(X_train_bow, y_train)\n",
    "\n",
    "acc = nb.score(X_test_bow, y_test)\n",
    "print(f'test acc: {acc: .1%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T14:32:48.972747Z",
     "start_time": "2020-09-04T14:32:48.966749Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment: 0\n"
     ]
    }
   ],
   "source": [
    "# predict the sentiment of a negative review\n",
    "review = \"The movie was terrible. The music was underwhelming and the acting mediocre.\"\n",
    "pred = nb.predict(vectorizer.transform([review]))[0]\n",
    "print(f'sentiment: {pred}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T14:32:19.346500Z",
     "start_time": "2020-09-04T14:32:19.340504Z"
    }
   },
   "source": [
    "# Building n-gram models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n-gram models for movie tag lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T14:37:42.110143Z",
     "start_time": "2020-09-04T14:37:42.105168Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus = overviews_['tagline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T14:40:29.987431Z",
     "start_time": "2020-09-04T14:40:28.988246Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ng1, ng2 and ng3 have 6614, 37100, and 76881 features, respectively\n"
     ]
    }
   ],
   "source": [
    "# generate n-grams upto n=1\n",
    "vectorizer_ng1 = CountVectorizer(ngram_range=(1, 1))\n",
    "ng1 = vectorizer_ng1.fit_transform(corpus)\n",
    "\n",
    "# generate n-grams upto n=2\n",
    "vectorizer_ng2 = CountVectorizer(ngram_range=(1, 2))\n",
    "ng2 = vectorizer_ng2.fit_transform(corpus)\n",
    "\n",
    "# generate n-grams upto n=3\n",
    "vectorizer_ng3 = CountVectorizer(ngram_range=(1, 3))\n",
    "ng3 = vectorizer_ng3.fit_transform(corpus)\n",
    "\n",
    "# Print the number of features for each model\n",
    "print(f'ng1, ng2 and ng3 have {ng1.shape[1]}, {ng2.shape[1]}, and {ng3.shape[1]} features, respectively')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `ng2` has over 37,000 features whereas `ng3` has over 76,000 features. This is much greater than the 6,000 dimensions obtained for `ng1`. As the n-gram range increases, so does the number of features, leading to increased computational costs and a problem known as the curse of dimensionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Higher order n-grams for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T14:47:55.428934Z",
     "start_time": "2020-09-04T14:47:55.420936Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.50,\n",
    "                                                    random_state=422)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T14:47:56.405301Z",
     "start_time": "2020-09-04T14:47:55.825039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (500, 57625)\n",
      "test shape: (500, 57625)\n"
     ]
    }
   ],
   "source": [
    "# create CountVectorizer object\n",
    "vectorizer = CountVectorizer(lowercase=True,\n",
    "                             stop_words='english',\n",
    "                             ngram_range=(1, 2))\n",
    "\n",
    "# transform data\n",
    "X_train_ng = vectorizer.fit_transform(X_train)\n",
    "X_test_ng = vectorizer.transform(X_test)\n",
    "\n",
    "print(f'train shape: {X_train_ng.shape}')\n",
    "print(f'test shape: {X_test_ng.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T14:47:57.055636Z",
     "start_time": "2020-09-04T14:47:57.039644Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc:  81.0%\n"
     ]
    }
   ],
   "source": [
    "# define an instance of MultinomialNB\n",
    "nb_ng = MultinomialNB()\n",
    "\n",
    "# fit and eval\n",
    "nb_ng.fit(X_train_ng, y_train)\n",
    "\n",
    "acc = nb_ng.score(X_test_ng, y_test)\n",
    "print(f'test acc: {acc: .1%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T14:47:58.036920Z",
     "start_time": "2020-09-04T14:47:58.029921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment predicted by the classifier is 0\n"
     ]
    }
   ],
   "source": [
    "# predict the sentiment of a negative review\n",
    "review = \"The movie was not good. The plot had several holes and the acting lacked panache.\"\n",
    "prediction = nb_ng.predict(vectorizer.transform([review]))[0]\n",
    "print(f'The sentiment predicted by the classifier is {prediction}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing performance of n-gram models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T14:54:30.000711Z",
     "start_time": "2020-09-04T14:54:29.684580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The program took  0.31 seconds to complete. The accuracy on the test set is  78.8%. The ngram representation had 11781 features.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "# Splitting the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.50,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=422)\n",
    "\n",
    "# Generating ngrams\n",
    "vectorizer = CountVectorizer(lowercase=True,\n",
    "                             stop_words='english',\n",
    "                             ngram_range=(1, 1))\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "# Fit classifier\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Print accuracy, time and number of dimensions\n",
    "print(f'The program took {time.time() - start_time: .2f} seconds to complete. The accuracy on the test set is {nb.score(X_test, y_test): .1%}. The ngram representation had {X_train.shape[1]} features.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T14:55:13.824625Z",
     "start_time": "2020-09-04T14:55:12.884381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The program took  0.92 seconds to complete. The accuracy on the test set is  79.2%. The ngram representation had 109901 features.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "# Splitting the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.50,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=422)\n",
    "\n",
    "# Generating ngrams\n",
    "vectorizer = CountVectorizer(lowercase=True,\n",
    "                             stop_words='english',\n",
    "                             ngram_range=(1, 3))\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "# Fit classifier\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Print accuracy, time and number of dimensions\n",
    "print(f'The program took {time.time() - start_time: .2f} seconds to complete. The accuracy on the test set is {nb.score(X_test, y_test): .1%}. The ngram representation had {X_train.shape[1]} features.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2-gpu",
   "language": "python",
   "name": "tf2-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
